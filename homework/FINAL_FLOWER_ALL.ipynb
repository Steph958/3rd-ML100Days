{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##https://medium.com/%E7%94%A8%E5%8A%9B%E5%8E%BB%E6%84%9B%E4%B8%80%E5%80%8B%E4%BA%BA%E7%9A%84%E8%A9%B1-%E5%BF%83%E4%B9%9F%E6%9C%83%E7%97%9B%E7%9A%84/%E9%BB%98%E9%BB%98%E5%9C%B0%E5%AD%B8deep-learning-4-698d00aba2ca\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import  img_to_array, load_img\n",
    "from PIL import Image\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellname:train\n",
      "concname:daisy\n",
      "daisy  finished!\n",
      "cellname:train\n",
      "concname:dandelion\n",
      "dandelion  finished!\n",
      "cellname:train\n",
      "concname:rose\n",
      "rose  finished!\n",
      "cellname:train\n",
      "concname:sunflower\n",
      "sunflower  finished!\n",
      "cellname:train\n",
      "concname:tulip\n",
      "tulip  finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_labels = {\"daisy\":0, \"dandelion\":1, \"rose\":2, \"sunflower\":3, \"tulip\":4}\n",
    "size = (256,256) #由於原始資料影像大小不一，因此制定一個統一值\n",
    "nbofdata=2000   #從各個資料夾中抓取特定數量的檔案\n",
    "#%% Read Traget Folders' Path\n",
    "labels=['daisy','dandelion','rose','sunflower','tulip']\n",
    "base_path = '../data/image_data/train/'\n",
    "layers_of_folders=0\n",
    "folder_list=[]\n",
    "if base_path :\n",
    "    folder_layers=[]\n",
    "    files = os.scandir(base_path)\n",
    "    #  Get the 1st layer of folder\n",
    "    first_folder = []\n",
    "    first_folder_kind = []\n",
    "    for entry in files:\n",
    "        if entry.is_dir():\n",
    "            first_folder.append(entry.path)\n",
    "            first_folder_kind.append(entry.name)\n",
    "    folder_layers.append(first_folder_kind)\n",
    "    folder_list.append(first_folder)\n",
    "    #  Get the 2nd layer of folder\n",
    "    second_folder = []\n",
    "    if first_folder:\n",
    "        second_folder = []\n",
    "        second_folder_kind = []\n",
    "        layers_of_folders+=1\n",
    "        for fldr in first_folder:\n",
    "            files = os.scandir(fldr)\n",
    "            for entry in files:\n",
    "                if entry.is_dir():\n",
    "                    second_folder.append(entry.path)\n",
    "                    second_folder_kind.append(entry.name)\n",
    "        second_folder_kind= second_folder_kind[0:int(len(second_folder_kind)/len(first_folder_kind))]\n",
    "        folder_layers.append(second_folder_kind)\n",
    "        folder_list.append(second_folder)\n",
    "    #  Get the 3rd layer of folder\n",
    "    third_folder = []\n",
    "    if second_folder:\n",
    "        third_folder = []\n",
    "        third_folder_kind = []\n",
    "        layers_of_folders+=1\n",
    "        for fldr in second_folder:\n",
    "            files = os.scandir(fldr)\n",
    "            for entry in files:\n",
    "                if entry.is_dir():\n",
    "                    third_folder.append(entry.path)\n",
    "                    third_folder_kind.append(entry.name)\n",
    "        third_folder_kind= third_folder_kind[0:int(len(third_folder_kind)/(len(second_folder_kind)*len(first_folder_kind)))]\n",
    "        folder_list.append(third_folder)\n",
    "    #  Get the 4th layer of folder\n",
    "    forth_folder = []\n",
    "    if third_folder:\n",
    "        forth_folder = []\n",
    "        forth_folder_kind = []\n",
    "        layers_of_folders+=1\n",
    "        for fldr in third_folder:\n",
    "            files = os.scandir(fldr)\n",
    "            for entry in files:\n",
    "                if entry.is_dir():\n",
    "                    forth_folder.append(entry.path)\n",
    "                    forth_folder_kind.append(entry.name)\n",
    "        forth_folder_kind= forth_folder_kind[0:int(len(forth_folder_kind)/(len(third_folder_kind)*len(second_folder_kind)*len(first_folder_kind)))]\n",
    "        folder_list.append(forth_folder)\n",
    "     #  Get the 5th layer of folder\n",
    "    if forth_folder:\n",
    "        fifth_folder = []\n",
    "        fifth_folder_kind = []\n",
    "        layers_of_folders+=1\n",
    "        for fldr in third_folder:\n",
    "            files = os.scandir(fldr)\n",
    "            for entry in files:\n",
    "                if entry.is_dir():\n",
    "                    fifth_folder.append(entry.path)\n",
    "                    fifth_folder_kind.append(entry.name)\n",
    "        fifth_folder_kind= fifth_folder_kind[0:int(len(fifth_folder_kind)/(len(forth_folder_kind)*len(third_folder_kind)*len(second_folder_kind)*len(first_folder_kind)))]\n",
    "#%% Read Image Files (*.tif)\n",
    "datanumber=nbofdata\n",
    "blob=[]\n",
    "blob_nparray=[]\n",
    "image_data=[]\n",
    "conc = 0\n",
    "labels_dict={}\n",
    "for entry1 in folder_list[layers_of_folders - 1]:\n",
    "    blob = []\n",
    "    cellname = os.path.basename(os.path.dirname(entry1))  # extract cell name\n",
    "    print('cellname:'+ cellname)\n",
    "    concnames = os.path.basename(entry1)  # extract concentration\n",
    "    print('concname:' +concnames)\n",
    "    if concnames in labels:\n",
    "        labels_dict[conc] = concnames\n",
    "        #print(entry1) \n",
    "        fnamelist = glob.glob(os.path.join(entry1, '*.jpg'))\n",
    "        for filename in fnamelist[0:datanumber]:\n",
    "            im = Image.open(filename)\n",
    "            if im is not None:\n",
    "                if im.mode=='RGB':\n",
    "                    im=im.resize(size,Image.BILINEAR)\n",
    "                    imarray = np.array(im)\n",
    "                    blob.append(imarray)\n",
    "        ind = np.reshape(np.arange(1, len(blob) + 1), (-1, 1))\n",
    "        blob_nparray = np.reshape(np.asarray(blob), (len(blob), blob[1].size))\n",
    "        blob_nparray = np.hstack((blob_nparray, ind, conc * np.ones((len(blob), 1))))\n",
    "        image_data.append(np.asarray(blob_nparray, dtype=np.float32))\n",
    "        print(concnames+'  finished!')\n",
    "        conc += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "for j in range(len(labels)):\n",
    "    trytry=image_data[j][:]\n",
    "# Prepare data\n",
    "    LengthT = trytry.shape[0]\n",
    "    trytry_index = trytry[...,-2:-1]\n",
    "    trytry_label = trytry[...,-1:] #['Nega' for x in range(lengthN*4)] #Nega_data[...,-1:]\n",
    "    trytry = trytry[...,:-2]\n",
    "    \n",
    "    # Normalize image by subtracting mean image\n",
    "    trytry -= np.reshape(np.mean(trytry, axis=1), (-1,1))\n",
    "    # Reshape images\n",
    "    trytry = np.reshape(trytry, (trytry.shape[0],256,256,3))\n",
    "    \n",
    "#    # Rotate images\n",
    "#    for i in range(3):\n",
    "#        trytry[LengthT*(i+1):LengthT*(i+2)] = np.rot90(trytry[:LengthT], i+1, (1,2))\n",
    "    # Add channel dimension to fit in Conv2D\n",
    "    trytry = trytry.reshape(-1,256,256,3)\n",
    "    np.random.shuffle(trytry)\n",
    "    trytry_train_upto = round(trytry.shape[0] * 8 / 10)  # 8成當訓練集\n",
    "    trytry_test_upto = trytry.shape[0]                   # 2成當測試集    \n",
    "    if j is 0:\n",
    "        train_data = trytry[:trytry_train_upto]\n",
    "        test_data = trytry[trytry_train_upto:trytry_test_upto]\n",
    "        train_label = trytry_label[:trytry_train_upto]\n",
    "        test_label = trytry_label[trytry_train_upto:trytry_test_upto]\n",
    "        \n",
    "    else:\n",
    "        train_data = np.concatenate((train_data, \n",
    "                                     trytry[:trytry_train_upto]), axis=0)\n",
    "        \n",
    "        test_data = np.concatenate((test_data, \n",
    "                                    trytry[trytry_train_upto:trytry_test_upto]), axis=0)\n",
    "        \n",
    "        train_label = np.concatenate((train_label, \n",
    "                                     trytry_label[:trytry_train_upto]), axis=0)\n",
    "        \n",
    "        \n",
    "        test_label = np.concatenate((test_label, \n",
    "                                    trytry_label[trytry_train_upto:trytry_test_upto]), axis=0)\n",
    "        \n",
    "test_label = keras.utils.to_categorical(test_label, num_classes=len(labels))\n",
    "train_label = keras.utils.to_categorical(train_label, num_classes=len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n",
      "565\n",
      "2258\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape[1])\n",
    "print(train_data.shape[1])\n",
    "print(len(test_label))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% Shuffle data\n",
    "import random\n",
    "temp = list(zip(train_data, train_label))\n",
    "\n",
    "random.shuffle(temp)\n",
    "\n",
    "train_data,train_label = zip(*temp)\n",
    "\n",
    "train_data=np.asarray(train_data)\n",
    "train_label=np.asarray(train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[   7.390915      7.390915      7.390915  ]\n",
      "   [   8.390915      8.390915      8.390915  ]\n",
      "   [   9.390915      9.390915      9.390915  ]\n",
      "   ...\n",
      "   [   2.390915      4.390915      3.390915  ]\n",
      "   [   0.39091492    2.390915      1.3909149 ]\n",
      "   [  -1.6090851     0.39091492   -0.6090851 ]]\n",
      "\n",
      "  [[   8.390915      8.390915      8.390915  ]\n",
      "   [   9.390915      9.390915      9.390915  ]\n",
      "   [  10.390915     10.390915     10.390915  ]\n",
      "   ...\n",
      "   [   3.390915      5.390915      4.390915  ]\n",
      "   [   1.3909149     3.390915      2.390915  ]\n",
      "   [  -0.6090851     1.3909149     0.39091492]]\n",
      "\n",
      "  [[  10.390915     10.390915     10.390915  ]\n",
      "   [  11.390915     11.390915     11.390915  ]\n",
      "   [  11.390915     11.390915     11.390915  ]\n",
      "   ...\n",
      "   [   2.390915      5.390915      4.390915  ]\n",
      "   [   2.390915      4.390915      3.390915  ]\n",
      "   [   0.39091492    2.390915      1.3909149 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ -35.609085    -39.609085    -42.609085  ]\n",
      "   [ -33.609085    -35.609085    -39.609085  ]\n",
      "   [ -33.609085    -34.609085    -38.609085  ]\n",
      "   ...\n",
      "   [ -39.609085    -43.609085    -46.609085  ]\n",
      "   [ -47.609085    -51.609085    -56.609085  ]\n",
      "   [ -51.609085    -54.609085    -59.609085  ]]\n",
      "\n",
      "  [[ -36.609085    -40.609085    -43.609085  ]\n",
      "   [ -37.609085    -38.609085    -42.609085  ]\n",
      "   [ -36.609085    -37.609085    -41.609085  ]\n",
      "   ...\n",
      "   [ -55.609085    -60.609085    -64.609085  ]\n",
      "   [ -58.609085    -62.609085    -66.609085  ]\n",
      "   [ -58.609085    -61.609085    -66.609085  ]]\n",
      "\n",
      "  [[ -40.609085    -41.609085    -45.609085  ]\n",
      "   [ -40.609085    -41.609085    -45.609085  ]\n",
      "   [ -39.609085    -40.609085    -44.609085  ]\n",
      "   ...\n",
      "   [ -62.609085    -70.609085    -73.609085  ]\n",
      "   [ -64.609085    -67.609085    -72.609085  ]\n",
      "   [ -62.609085    -65.609085    -70.609085  ]]]\n",
      "\n",
      "\n",
      " [[[ -21.299362    -21.299362    -21.299362  ]\n",
      "   [ -22.299362    -22.299362    -22.299362  ]\n",
      "   [ -21.299362    -21.299362    -21.299362  ]\n",
      "   ...\n",
      "   [ -24.299362    -24.299362    -24.299362  ]\n",
      "   [ -24.299362    -24.299362    -24.299362  ]\n",
      "   [ -24.299362    -24.299362    -24.299362  ]]\n",
      "\n",
      "  [[ -22.299362    -22.299362    -22.299362  ]\n",
      "   [ -23.299362    -23.299362    -23.299362  ]\n",
      "   [ -22.299362    -22.299362    -22.299362  ]\n",
      "   ...\n",
      "   [ -24.299362    -24.299362    -24.299362  ]\n",
      "   [ -24.299362    -24.299362    -24.299362  ]\n",
      "   [ -24.299362    -24.299362    -24.299362  ]]\n",
      "\n",
      "  [[ -23.299362    -23.299362    -23.299362  ]\n",
      "   [ -23.299362    -23.299362    -23.299362  ]\n",
      "   [ -23.299362    -23.299362    -23.299362  ]\n",
      "   ...\n",
      "   [ -24.299362    -24.299362    -24.299362  ]\n",
      "   [ -24.299362    -24.299362    -24.299362  ]\n",
      "   [ -24.299362    -24.299362    -24.299362  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ -21.299362    -21.299362    -21.299362  ]\n",
      "   [ -18.299362    -18.299362    -18.299362  ]\n",
      "   [ -14.299362    -14.299362    -14.299362  ]\n",
      "   ...\n",
      "   [ -21.299362    -21.299362    -21.299362  ]\n",
      "   [ -20.299362    -20.299362    -20.299362  ]\n",
      "   [ -20.299362    -20.299362    -20.299362  ]]\n",
      "\n",
      "  [[ -19.299362    -19.299362    -19.299362  ]\n",
      "   [ -16.299362    -16.299362    -16.299362  ]\n",
      "   [ -11.299362    -11.299362    -11.299362  ]\n",
      "   ...\n",
      "   [ -19.299362    -19.299362    -19.299362  ]\n",
      "   [ -18.299362    -18.299362    -18.299362  ]\n",
      "   [ -17.299362    -17.299362    -17.299362  ]]\n",
      "\n",
      "  [[ -16.299362    -16.299362    -16.299362  ]\n",
      "   [ -12.299362    -12.299362    -12.299362  ]\n",
      "   [  -8.299362     -8.299362     -8.299362  ]\n",
      "   ...\n",
      "   [ -18.299362    -18.299362    -18.299362  ]\n",
      "   [ -18.299362    -18.299362    -18.299362  ]\n",
      "   [ -17.299362    -17.299362    -17.299362  ]]]\n",
      "\n",
      "\n",
      " [[[ -26.6997      -33.6997      -41.6997    ]\n",
      "   [ -40.6997      -54.6997      -57.6997    ]\n",
      "   [ -57.6997      -76.6997      -78.6997    ]\n",
      "   ...\n",
      "   [ -70.6997      -57.6997      -74.6997    ]\n",
      "   [ -74.6997      -59.6997      -76.6997    ]\n",
      "   [ -70.6997      -53.6997      -71.6997    ]]\n",
      "\n",
      "  [[  -7.6996994   -10.699699    -17.6997    ]\n",
      "   [ -17.6997      -28.6997      -31.6997    ]\n",
      "   [ -38.6997      -54.6997      -55.6997    ]\n",
      "   ...\n",
      "   [ -69.6997      -55.6997      -73.6997    ]\n",
      "   [ -73.6997      -58.6997      -75.6997    ]\n",
      "   [ -73.6997      -58.6997      -75.6997    ]]\n",
      "\n",
      "  [[  19.3003       20.3003       16.3003    ]\n",
      "   [  14.300301      7.3003006     4.3003006 ]\n",
      "   [ -10.699699    -23.6997      -23.6997    ]\n",
      "   ...\n",
      "   [ -67.6997      -53.6997      -71.6997    ]\n",
      "   [ -71.6997      -57.6997      -74.6997    ]\n",
      "   [ -76.6997      -64.6997      -81.6997    ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  89.3003       77.3003       75.3003    ]\n",
      "   [  66.3003      -13.699699     -4.6996994 ]\n",
      "   [  58.3003      -31.6997      -34.6997    ]\n",
      "   ...\n",
      "   [ -85.6997      -75.6997      -84.6997    ]\n",
      "   [ -86.6997      -73.6997      -83.6997    ]\n",
      "   [ -70.6997      -50.6997      -62.6997    ]]\n",
      "\n",
      "  [[  86.3003       82.3003       79.3003    ]\n",
      "   [  68.3003        3.3003006     8.300301  ]\n",
      "   [  66.3003      -15.699699    -21.6997    ]\n",
      "   ...\n",
      "   [ -85.6997      -74.6997      -82.6997    ]\n",
      "   [ -88.6997      -72.6997      -82.6997    ]\n",
      "   [ -73.6997      -53.6997      -64.6997    ]]\n",
      "\n",
      "  [[  83.3003       85.3003       82.3003    ]\n",
      "   [  69.3003       15.300301     17.3003    ]\n",
      "   [  72.3003       -2.6996994   -10.699699  ]\n",
      "   ...\n",
      "   [ -85.6997      -73.6997      -81.6997    ]\n",
      "   [ -89.6997      -72.6997      -82.6997    ]\n",
      "   [ -75.6997      -55.6997      -66.6997    ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[  -5.7946777    -4.7946777   -17.794678  ]\n",
      "   [   0.20532227    1.2053223    -8.794678  ]\n",
      "   [  -9.794678     -8.794678    -24.794678  ]\n",
      "   ...\n",
      "   [ -41.794678    -39.794678    -41.794678  ]\n",
      "   [ -41.794678    -39.794678    -41.794678  ]\n",
      "   [ -41.794678    -39.794678    -41.794678  ]]\n",
      "\n",
      "  [[   3.2053223     2.2053223   -12.794678  ]\n",
      "   [ -10.794678     -9.794678    -22.794678  ]\n",
      "   [ -27.794678    -25.794678    -38.794678  ]\n",
      "   ...\n",
      "   [ -41.794678    -39.794678    -41.794678  ]\n",
      "   [ -41.794678    -39.794678    -41.794678  ]\n",
      "   [ -41.794678    -39.794678    -41.794678  ]]\n",
      "\n",
      "  [[  10.205322      9.205322     -9.794678  ]\n",
      "   [  -6.7946777    -5.7946777   -23.794678  ]\n",
      "   [ -29.794678    -27.794678    -39.794678  ]\n",
      "   ...\n",
      "   [ -41.794678    -39.794678    -41.794678  ]\n",
      "   [ -41.794678    -39.794678    -41.794678  ]\n",
      "   [ -41.794678    -39.794678    -41.794678  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ -31.794678    -36.794678    -41.794678  ]\n",
      "   [ -36.794678    -39.794678    -41.794678  ]\n",
      "   [ -40.794678    -40.794678    -41.794678  ]\n",
      "   ...\n",
      "   [ -41.794678    -41.794678    -41.794678  ]\n",
      "   [ -41.794678    -41.794678    -41.794678  ]\n",
      "   [ -41.794678    -41.794678    -41.794678  ]]\n",
      "\n",
      "  [[ -28.794678    -32.794678    -40.794678  ]\n",
      "   [ -33.794678    -36.794678    -41.794678  ]\n",
      "   [ -38.794678    -39.794678    -41.794678  ]\n",
      "   ...\n",
      "   [ -41.794678    -41.794678    -41.794678  ]\n",
      "   [ -41.794678    -41.794678    -41.794678  ]\n",
      "   [ -41.794678    -41.794678    -41.794678  ]]\n",
      "\n",
      "  [[ -26.794678    -30.794678    -41.794678  ]\n",
      "   [ -31.794678    -34.794678    -41.794678  ]\n",
      "   [ -37.794678    -38.794678    -41.794678  ]\n",
      "   ...\n",
      "   [ -41.794678    -41.794678    -41.794678  ]\n",
      "   [ -41.794678    -41.794678    -41.794678  ]\n",
      "   [ -41.794678    -41.794678    -41.794678  ]]]\n",
      "\n",
      "\n",
      " [[[ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   ...\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]]\n",
      "\n",
      "  [[ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   ...\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]]\n",
      "\n",
      "  [[ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   ...\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]\n",
      "   [ 110.85097     110.85097     110.85097   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 106.85097     108.85097     104.85097   ]\n",
      "   [ 108.85097     110.85097     106.85097   ]\n",
      "   [ 110.85097     110.85097     109.85097   ]\n",
      "   ...\n",
      "   [ -11.149033     -8.149033    -26.149033  ]\n",
      "   [ -53.149033    -48.149033    -73.14903   ]\n",
      "   [ -61.149033    -55.149033    -78.14903   ]]\n",
      "\n",
      "  [[ 108.85097     108.85097     106.85097   ]\n",
      "   [ 109.85097     109.85097     107.85097   ]\n",
      "   [ 110.85097     110.85097     108.85097   ]\n",
      "   ...\n",
      "   [  56.850967     53.850967     47.850967  ]\n",
      "   [ -29.149033    -27.149033    -49.149033  ]\n",
      "   [ -54.149033    -47.149033    -70.14903   ]]\n",
      "\n",
      "  [[ 109.85097     109.85097     107.85097   ]\n",
      "   [ 109.85097     109.85097     107.85097   ]\n",
      "   [ 110.85097     110.85097     108.85097   ]\n",
      "   ...\n",
      "   [  84.85097      82.85097      76.85097   ]\n",
      "   [  -9.149033     -7.1490326   -28.149033  ]\n",
      "   [ -44.149033    -37.149033    -58.149033  ]]]\n",
      "\n",
      "\n",
      " [[[ 151.50018     151.50018     151.50018   ]\n",
      "   [ 151.50018     151.50018     151.50018   ]\n",
      "   [ 151.50018     151.50018     151.50018   ]\n",
      "   ...\n",
      "   [ -97.49982     -95.49982     -98.49982   ]\n",
      "   [-103.49982    -100.49982    -103.49982   ]\n",
      "   [ -99.49982     -92.49982     -99.49982   ]]\n",
      "\n",
      "  [[ 151.50018     151.50018     151.50018   ]\n",
      "   [ 151.50018     151.50018     151.50018   ]\n",
      "   [ 151.50018     151.50018     151.50018   ]\n",
      "   ...\n",
      "   [ -65.49982     -63.499817    -66.49982   ]\n",
      "   [-101.49982     -98.49982    -101.49982   ]\n",
      "   [-101.49982     -95.49982    -101.49982   ]]\n",
      "\n",
      "  [[ 151.50018     151.50018     151.50018   ]\n",
      "   [ 151.50018     151.50018     151.50018   ]\n",
      "   [ 151.50018     151.50018     151.50018   ]\n",
      "   ...\n",
      "   [ -23.499817    -21.499817    -24.499817  ]\n",
      "   [ -99.49982     -95.49982     -98.49982   ]\n",
      "   [-103.49982    -100.49982    -103.49982   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ -50.499817    -20.499817    -20.499817  ]\n",
      "   [ -47.499817    -12.499817    -14.499817  ]\n",
      "   [  -6.499817     14.500183     17.500183  ]\n",
      "   ...\n",
      "   [ -26.499817    -28.499817    -27.499817  ]\n",
      "   [ -58.499817    -56.499817    -57.499817  ]\n",
      "   [ -83.49982     -79.49982     -80.49982   ]]\n",
      "\n",
      "  [[ -56.499817    -22.499817    -24.499817  ]\n",
      "   [ -53.499817    -14.499817    -19.499817  ]\n",
      "   [ -22.499817      3.500183      4.500183  ]\n",
      "   ...\n",
      "   [ -27.499817    -30.499817    -31.499817  ]\n",
      "   [ -54.499817    -54.499817    -55.499817  ]\n",
      "   [ -82.49982     -80.49982     -82.49982   ]]\n",
      "\n",
      "  [[ -59.499817    -23.499817    -27.499817  ]\n",
      "   [ -57.499817    -15.499817    -22.499817  ]\n",
      "   [ -35.499817     -5.499817     -5.499817  ]\n",
      "   ...\n",
      "   [ -27.499817    -30.499817    -33.499817  ]\n",
      "   [ -51.499817    -52.499817    -54.499817  ]\n",
      "   [ -80.49982     -80.49982     -82.49982   ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1806 samples, validate on 452 samples\n",
      "Epoch 1/35\n",
      "1806/1806 [==============================] - 334s 185ms/step - loss: 0.6131 - accuracy: 0.7555 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
      "Epoch 2/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806/1806 [==============================] - 371s 205ms/step - loss: 0.5093 - accuracy: 0.7831 - val_loss: 0.4634 - val_accuracy: 0.7996\n",
      "Epoch 3/35\n",
      "1806/1806 [==============================] - 494s 274ms/step - loss: 0.4752 - accuracy: 0.7897 - val_loss: 0.4340 - val_accuracy: 0.8062\n",
      "Epoch 4/35\n",
      "1806/1806 [==============================] - 599s 332ms/step - loss: 0.4482 - accuracy: 0.7998 - val_loss: 0.3920 - val_accuracy: 0.8168\n",
      "Epoch 5/35\n",
      "1806/1806 [==============================] - 648s 359ms/step - loss: 0.4294 - accuracy: 0.8116 - val_loss: 0.4038 - val_accuracy: 0.8296\n",
      "Epoch 6/35\n",
      "1806/1806 [==============================] - 780s 432ms/step - loss: 0.4114 - accuracy: 0.8179 - val_loss: 0.3562 - val_accuracy: 0.8465\n",
      "Epoch 7/35\n",
      "1804/1806 [============================>.] - ETA: 0s - loss: 0.3981 - accuracy: 0.8307"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% VGG 16 only for classification\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "# Generate model\n",
    "model = Sequential()\n",
    "# input: 190x190 images with 3 channels -> (190, 190, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(256,256,3),padding='same',name='block1_conv2_1'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',name='block1_conv2_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block1_MaxPooling'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',name='block2_conv2_1'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',name='block2_conv2_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block2_MaxPooling'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_1'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_2'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same',name='block3_conv2_3'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block3_MaxPooling'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_1'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_2'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block4_conv2_3'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block4_MaxPooling'))\n",
    "model.add(Dropout(0.25))\n",
    "#\n",
    "#model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block5_conv2_1'))\n",
    "#model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block5_conv2_2'))\n",
    "#model.add(Conv2D(512, (3, 3), activation='relu',padding='same',name='block5_conv2_3'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2),name='block5_MaxPooling'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu',name='final_output_1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu',name='final_output_2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='sigmoid',name='class_output'))  #OUTPUT LAYER \n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "EStop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                      patience=10, verbose=1, mode='auto')\n",
    "#%% Start Traning Model\n",
    "history = model.fit(train_data, train_label, batch_size=4, epochs=35 ,shuffle=True, validation_split=0.2,callbacks=[EStop])\n",
    "#%%\n",
    "model.save('catdog_model1228256.h5') \n",
    "predictions=model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入模型\n",
    "model = keras.models.load_model('catdog_model1228256.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "# 準備 x_test 與 y_test 資料 ... [略]\n",
    "size = (256, 256)\n",
    "nbofdata=2000\n",
    "base_path = '../data/image_data/test/'\n",
    "layers_of_folders=0\n",
    "folder_list=[]    \n",
    "labels=['test']\n",
    "\n",
    "if base_path :\n",
    "    folder_layers=[]\n",
    "    files = os.scandir(base_path)\n",
    "    #  Get the 1st layer of folder\n",
    "    first_folder = []\n",
    "    first_folder_kind = []\n",
    "    for entry in files:\n",
    "        if entry.is_dir():\n",
    "            first_folder.append(entry.path)\n",
    "            first_folder_kind.append(entry.name)\n",
    "    folder_layers.append(first_folder_kind)\n",
    "    folder_list.append(first_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanumber=nbofdata\n",
    "blob=[]\n",
    "blob_nparray=[]\n",
    "image_data=[]\n",
    "conc = 0\n",
    "fc = 0\n",
    "labels_dict={}\n",
    "fn = {}\n",
    "for entry1 in folder_list[layers_of_folders - 1]:\n",
    "    blob = []\n",
    "    cellname = os.path.basename(os.path.dirname(entry1))  # extract cell name\n",
    "    # print(cellname)\n",
    "    concnames = os.path.basename(entry1)  # extract concentration\n",
    "    # print(concnames)\n",
    "    if concnames in labels:\n",
    "        labels_dict[conc] = concnames\n",
    "        fnamelist = glob.glob(os.path.join(entry1, '*.jpg'))\n",
    "        for filename in fnamelist[0:datanumber]:\n",
    "            im = Image.open(filename)\n",
    "            if im is not None:\n",
    "                if im.mode=='RGB':\n",
    "                    im=im.resize(size,Image.BILINEAR)\n",
    "                    imarray = np.array(im)\n",
    "                    blob.append(imarray)\n",
    "                    fn[fc] = filename\n",
    "                    fc += 1\n",
    "        ind = np.reshape(np.arange(1, len(blob) + 1), (-1, 1))\n",
    "        blob_nparray = np.reshape(np.asarray(blob), (len(blob), blob[1].size))\n",
    "        blob_nparray = np.hstack((blob_nparray, ind, conc * np.ones((len(blob), 1))))\n",
    "        image_data.append(np.asarray(blob_nparray, dtype=np.float32))\n",
    "        print(ind)\n",
    "        print(blob_nparray)\n",
    "        print(concnames+'  finished!')\n",
    "        conc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = {}\n",
    "for i in range(2000):\n",
    "    sp[i] = fn[i].split('/')\n",
    "    sp[i] = sp[i][4].split('test\\\\')\n",
    "    sp[i] = sp[i][1].split('.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(sp[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {}\n",
    "for i in range(2000):\n",
    "    ids[i] = sp[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(labels)):\n",
    "    trytry=image_data[j][:]\n",
    "# Prepare data\n",
    "    LengthT = trytry.shape[0]\n",
    "\n",
    "    trytry_index = trytry[...,-2:-1]\n",
    "\n",
    "    trytry_label = trytry[...,-1:] #['Nega' for x in range(lengthN*4)] #Nega_data[...,-1:]\n",
    "\n",
    "    trytry = trytry[...,:-2]\n",
    "\n",
    "    # Normalize image by subtracting mean image\n",
    "    trytry -= np.reshape(np.mean(trytry, axis=1), (-1,1))\n",
    "    # Reshape images\n",
    "    trytry = np.reshape(trytry, (trytry.shape[0],256,256,3))\n",
    "    \n",
    "#    # Rotate images\n",
    "#    for i in range(3):\n",
    "#        trytry[LengthT*(i+1):LengthT*(i+2)] = np.rot90(trytry[:LengthT], i+1, (1,2))\n",
    "    # Add channel dimension to fit in Conv2D\n",
    "    trytry = trytry.reshape(-1,256,256,3)\n",
    "    trytry_test_upto = trytry.shape[0]\n",
    "    if j is 0:\n",
    "        test_data = trytry[:trytry_test_upto]      \n",
    "    else:     \n",
    "        test_data = np.concatenate((test_data, \n",
    "                                    trytry[trytry_train_upto:trytry_test_upto]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        print(predictions[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "plt.imshow(array_to_img(test_data[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred = {}\n",
    "for i in range(2000):\n",
    "    for j in range(5):\n",
    "        if predictions[i][j] == np.max(predictions[i]):\n",
    "            if j == 0:\n",
    "                cnn_pred[i] = 0\n",
    "            if j == 1:\n",
    "                cnn_pred[i] = 1\n",
    "            if j == 2:\n",
    "                cnn_pred[i] = 2\n",
    "            if j == 3:\n",
    "                cnn_pred[i] = 3\n",
    "            if j == 4:\n",
    "                cnn_pred[i] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "submit = pd.DataFrame({'id': ids, 'flower_class': cnn_pred})\n",
    "header = [\"id\", \"flower_class\"]\n",
    "submit.to_csv('cnn_resnet_JIMMY2.csv', columns = header, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
