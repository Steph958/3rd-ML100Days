{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業重點:\n",
    "\n",
    "(1)以, Adam, 為例, 調整 batch_size, epoch , 觀察accurancy, loss 的變化\n",
    "\n",
    "(2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業目標:\n",
    "    \n",
    "    取得各種優化器的運算結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n",
    "#import tensorflow as tf\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "   宣告並設定\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs ：訓練次數\n",
    "   \n",
    "''' \n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 40\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    第一步：選擇模型, 順序模型是多個網絡層的線性堆疊\n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "#   第二步：構建網絡層\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense( 10)) # 輸出結果是10個類別，所以維度是10   \n",
    "model.add(Activation('softmax')) # 最後一層用softmax作為激活函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters：1250858\n"
     ]
    }
   ],
   "source": [
    "# 模型建立完成後，統計參數總量\n",
    "print(\"Total Parameters：%d\" % model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 輸出模型摘要資訊\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第三步編譯\n",
    "'''\n",
    " SGD(隨機梯度下降) - Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "momentum: float >= 0. Parameter that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "'''\n",
    "\n",
    "'''\n",
    "RMSprop- Arguments\n",
    "lr: float >= 0. Learning rate.\n",
    "rho: float >= 0.\n",
    "epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().\n",
    "decay: float >= 0. Learning rate decay over each update.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Example:\n",
    "opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "'''\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料正規化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 1.5497 - accuracy: 0.4303 - val_loss: 1.2445 - val_accuracy: 0.5515\n",
      "Epoch 2/40\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 1.1743 - accuracy: 0.5844 - val_loss: 0.9964 - val_accuracy: 0.6519\n",
      "Epoch 3/40\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.9935 - accuracy: 0.6475 - val_loss: 0.8566 - val_accuracy: 0.7022\n",
      "Epoch 4/40\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.8891 - accuracy: 0.6880 - val_loss: 0.8171 - val_accuracy: 0.7123\n",
      "Epoch 5/40\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.8087 - accuracy: 0.7152 - val_loss: 0.7560 - val_accuracy: 0.7359\n",
      "Epoch 6/40\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.7585 - accuracy: 0.7321 - val_loss: 0.7150 - val_accuracy: 0.7507\n",
      "Epoch 7/40\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.7175 - accuracy: 0.7479 - val_loss: 0.7325 - val_accuracy: 0.7467\n",
      "Epoch 8/40\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.6821 - accuracy: 0.7590 - val_loss: 0.6775 - val_accuracy: 0.7690\n",
      "Epoch 9/40\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.6450 - accuracy: 0.7736 - val_loss: 0.6502 - val_accuracy: 0.7756\n",
      "Epoch 10/40\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.6187 - accuracy: 0.7817 - val_loss: 0.6426 - val_accuracy: 0.7769\n",
      "Epoch 11/40\n",
      "50000/50000 [==============================] - 128s 3ms/step - loss: 0.5930 - accuracy: 0.7911 - val_loss: 0.6508 - val_accuracy: 0.7765\n",
      "Epoch 12/40\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.5680 - accuracy: 0.7993 - val_loss: 0.6273 - val_accuracy: 0.7882\n",
      "Epoch 13/40\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 0.5542 - accuracy: 0.8042 - val_loss: 0.6286 - val_accuracy: 0.7805\n",
      "Epoch 14/40\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.5354 - accuracy: 0.8088 - val_loss: 0.6367 - val_accuracy: 0.7864\n",
      "Epoch 15/40\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.5114 - accuracy: 0.8185 - val_loss: 0.6146 - val_accuracy: 0.7915\n",
      "Epoch 16/40\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.5023 - accuracy: 0.8219 - val_loss: 0.6340 - val_accuracy: 0.7876\n",
      "Epoch 17/40\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.4873 - accuracy: 0.8263 - val_loss: 0.6199 - val_accuracy: 0.7914\n",
      "Epoch 18/40\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.4737 - accuracy: 0.8311 - val_loss: 0.6053 - val_accuracy: 0.7992\n",
      "Epoch 19/40\n",
      "50000/50000 [==============================] - 138s 3ms/step - loss: 0.4582 - accuracy: 0.8376 - val_loss: 0.6665 - val_accuracy: 0.7870\n",
      "Epoch 20/40\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 0.4488 - accuracy: 0.8409 - val_loss: 0.6241 - val_accuracy: 0.7941\n",
      "Epoch 21/40\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4425 - accuracy: 0.8424 - val_loss: 0.6242 - val_accuracy: 0.7902\n",
      "Epoch 22/40\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4276 - accuracy: 0.8479 - val_loss: 0.6147 - val_accuracy: 0.7996\n",
      "Epoch 23/40\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4227 - accuracy: 0.8499 - val_loss: 0.6174 - val_accuracy: 0.7981\n",
      "Epoch 24/40\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.4127 - accuracy: 0.8546 - val_loss: 0.6310 - val_accuracy: 0.8001\n",
      "Epoch 25/40\n",
      "50000/50000 [==============================] - 143s 3ms/step - loss: 0.4071 - accuracy: 0.8548 - val_loss: 0.6301 - val_accuracy: 0.7943\n",
      "Epoch 26/40\n",
      "50000/50000 [==============================] - 142s 3ms/step - loss: 0.4016 - accuracy: 0.8561 - val_loss: 0.6479 - val_accuracy: 0.8014\n",
      "Epoch 27/40\n",
      "50000/50000 [==============================] - 147s 3ms/step - loss: 0.3996 - accuracy: 0.8588 - val_loss: 0.6097 - val_accuracy: 0.8019\n",
      "Epoch 28/40\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.3892 - accuracy: 0.8603 - val_loss: 0.6496 - val_accuracy: 0.7992\n",
      "Epoch 29/40\n",
      "50000/50000 [==============================] - 144s 3ms/step - loss: 0.3874 - accuracy: 0.8643 - val_loss: 0.6316 - val_accuracy: 0.7978\n",
      "Epoch 30/40\n",
      "34944/50000 [===================>..........] - ETA: 30:52 - loss: 0.3759 - accuracy: 0.8669"
     ]
    }
   ],
   "source": [
    "# 是否要做資料處理\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history=model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    print('')\n",
    "        \n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "    history=model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)   \n",
    "\n",
    "'''\n",
    "   第四步：訓練\n",
    "   .fit的一些參數\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs ：訓練次數\n",
    "   shuffle：是否把數據隨機打亂之後再進行訓練\n",
    "   validation_split：拿出百分之多少用來做交叉驗證\n",
    "   verbose：屏顯模式 - 0：不輸出, 1：輸出進度, 2：輸出每次的訓練結果\n",
    "''' \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    第六步：輸出\n",
    "import numpy \n",
    "\n",
    "print ( \" test set \" )\n",
    "scores = model.evaluate(x_test,y_test,batch_size=200,verbose= 0)\n",
    "print ( \"\" )\n",
    "#print ( \" The test loss is %f \" % scores)\n",
    "print ( \" The test loss is %f \", scores)\n",
    "\n",
    "\n",
    "result = model.predict(x_test,batch_size=200,verbose= 0)\n",
    "\n",
    "result_max = numpy.argmax(result, axis = 1 )\n",
    "test_max = numpy.argmax(y_test, axis = 1 )\n",
    "\n",
    "result_bool = numpy.equal(result_max, test_max)\n",
    "true_num = numpy.sum(result_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valiidation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valiidation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
